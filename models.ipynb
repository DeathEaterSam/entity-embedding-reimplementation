{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(123)\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to fetch previously saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_features(X, saved_embeddings_fname):\n",
    "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
    "    f_embeddings = open(saved_embeddings_fname, \"rb\") # Open the pickle file\n",
    "    embeddings = pickle.load(f_embeddings) # Load it\n",
    "\n",
    "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5} # The values are the indices of the embedded features\n",
    "    X_embedded = []\n",
    "\n",
    "    (num_records, num_features) = X.shape\n",
    "    for record in X:\n",
    "        embedded_features = []\n",
    "        for i, feat in enumerate(record):\n",
    "            feat = int(feat)\n",
    "            if i not in index_embedding_mapping.keys():\n",
    "                embedded_features += [feat]\n",
    "            else:\n",
    "                embedding_index = index_embedding_mapping[i]\n",
    "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
    "\n",
    "        X_embedded.append(embedded_features)\n",
    "\n",
    "    return numpy.array(X_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function takes the input data and returns a list of each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "\n",
    "    store_index = X[..., [1]]\n",
    "    X_list.append(store_index)\n",
    "\n",
    "    day_of_week = X[..., [2]]\n",
    "    X_list.append(day_of_week)\n",
    "\n",
    "    promo = X[..., [3]]\n",
    "    X_list.append(promo)\n",
    "\n",
    "    year = X[..., [4]]\n",
    "    X_list.append(year)\n",
    "\n",
    "    month = X[..., [5]]\n",
    "    X_list.append(month)\n",
    "\n",
    "    day = X[..., [6]]\n",
    "    X_list.append(day)\n",
    "\n",
    "    State = X[..., [7]]\n",
    "    X_list.append(State)\n",
    "\n",
    "    return numpy.array(X_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val)\n",
    "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = numpy.sum(relative_err) / len(y_val)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = linear_model.LinearRegression() # this is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = RandomForestRegressor(n_estimators=200, verbose=True, max_depth=35, min_samples_split=2,\n",
    "                                         min_samples_leaf=1) # This is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement support vector machine regression because they used sklearn, i copied it please dont DC us\n",
    "class SVM(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.__normalize_data()\n",
    "        self.clf = SVR(kernel='linear', degree=3, gamma='auto', coef0=0.0, tol=0.001,\n",
    "                    C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "        self.clf.fit(self.X_train, torch.log(self.y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def __normalize_data(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return torch.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost(Model):\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        dtrain = xgb.DMatrix(X_train, label= torch.log(y_train))\n",
    "        evallist = [(dtrain, 'train')]\n",
    "        param = {'nthread': -1,\n",
    "                'max_depth': 7,\n",
    "                'eta': 0.02,\n",
    "                'silent': 1,\n",
    "                'objective': 'reg:linear',\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample': 0.7}\n",
    "        num_round = 3000\n",
    "        self.bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        dtest = xgb.DMatrix(feature)\n",
    "        return numpy.exp(self.bst.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistricalMedian(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.history = {}\n",
    "        self.feature_index = [1, 2, 3, 4]\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            key = tuple(x[self.feature_index])\n",
    "            self.history.setdefault(key, []).append(y)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        features = numpy.array(features)\n",
    "        features = features[:, self.feature_index]\n",
    "        guessed_sales = [numpy.median(self.history[tuple(feature)]) for feature in features]\n",
    "        return numpy.array(guessed_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.normalizer = Normalizer()\n",
    "        self.normalizer.fit(X_train)\n",
    "        self.clf = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance', p=1)\n",
    "        self.clf.fit(self.normalizer.transform(X_train), numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(self.normalizer.transform(X_val), y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(self.normalizer.transform(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_with_EntityEmbedding(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.one = nn.Sequential(nn.Embedding(1115, 10), nn.Flatten())\n",
    "        self.two = nn.Sequential(nn.Embedding(7, 6), nn.Flatten())\n",
    "        self.three = nn.Linear(1,1)\n",
    "        self.four = nn.Sequential(nn.Embedding(3, 2), nn.Flatten())\n",
    "        self.five = nn.Sequential(nn.Embedding(12, 6), nn.Flatten())\n",
    "        self.six = nn.Sequential(nn.Embedding(31, 10), nn.Flatten())\n",
    "        self.seven = nn.Sequential(nn.Embedding(21, 6), nn.Flatten())\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(41, 1000),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        nn.init.xavier_normal_(self.network[4].weight)\n",
    "        self.to(device)\n",
    "        self.fit(X_train,y_train, X_val, y_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        one = self.one(x[:,[1]])\n",
    "        two = self.two(x[:,[2]])\n",
    "        three=self.three(x[:, [3]].float())\n",
    "        four=self.four(x[:, [4]])\n",
    "        five=self.five(x[:,[5]])\n",
    "        six=self.six(x[:, [6]])\n",
    "        seven = self.seven(x[:, [7]])\n",
    "        concat = torch.cat([one, two, three, four, five, six, seven], dim=1)\n",
    "        output = self.network(concat)\n",
    "        return output\n",
    "    \n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val)/self.max_log_y\n",
    "    \n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val*self.max_log_y)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=False)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                print(\"Result on validation data: \", self.evaluate(X_val.to(device), y_val.to(device)))\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val) # Guess is implemented in children classes for inference\n",
    "        relative_err = torch.absolute((y_val - guessed_sales) / y_val) \n",
    "        result = torch.sum(relative_err) / len(y_val)\n",
    "        return result\n",
    "    \n",
    "    def guess(self, features):\n",
    "        with torch.inference_mode():\n",
    "            result = self.forward(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on validation data:  tensor(0.1160, device='cuda:0')\n",
      "Result on validation data:  tensor(0.1068, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0899, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0845, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0836, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0820, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0795, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0805, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0790, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0786, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with open('feature_train_data.pickle', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = NN_with_EntityEmbedding(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super(NN, self).__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1183, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.to(device)\n",
    "        self.fit(X_train,y_train, X_val, y_val)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val) / self.max_log_y\n",
    "\n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val * self.max_log_y)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=False)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.float().to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                print(\n",
    "                    \"Result on validation data: \",\n",
    "                    self.evaluate(X_val.float().to(device), y_val.to(device)),\n",
    "                )\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert (\n",
    "            min(y_val) > 0\n",
    "        )  # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(\n",
    "            X_val\n",
    "        )  # Guess is implemented in children classes for inference\n",
    "        relative_err = torch.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = torch.sum(relative_err) / len(y_val)\n",
    "        return result\n",
    "\n",
    "    def guess(self, features):\n",
    "        with torch.no_grad():\n",
    "            result = self.model(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on validation data:  tensor(0.0880, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0810, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0721, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0709, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0715, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0687, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0689, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0746, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0748, device='cuda:0')\n",
      "Result on validation data:  tensor(0.0706, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = NN(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
