{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Normalizer, OneHotEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to fetch previously saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_features(X, saved_embeddings_fname):\n",
    "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
    "    f_embeddings = open(saved_embeddings_fname, \"rb\") # Open the pickle file\n",
    "    embeddings = pickle.load(f_embeddings) # Load it\n",
    "\n",
    "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5} # The values are the indices of the embedded features\n",
    "    X_embedded = []\n",
    "\n",
    "    (num_records, num_features) = X.shape\n",
    "    for record in X:\n",
    "        embedded_features = []\n",
    "        for i, feat in enumerate(record):\n",
    "            feat = int(feat)\n",
    "            if i not in index_embedding_mapping.keys():\n",
    "                embedded_features += [feat]\n",
    "            else:\n",
    "                embedding_index = index_embedding_mapping[i]\n",
    "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
    "\n",
    "        X_embedded.append(embedded_features)\n",
    "\n",
    "    return numpy.array(X_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val)\n",
    "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = numpy.sum(relative_err) / len(y_val)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = linear_model.LinearRegression() # this is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = RandomForestRegressor(n_estimators=200, verbose=True, max_depth=35, min_samples_split=2,\n",
    "                                         min_samples_leaf=1) # This is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement support vector machine regression because they used sklearn, i copied it please dont DC us\n",
    "class SVM(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.__normalize_data()\n",
    "        self.clf = SVR(kernel='linear', degree=3, gamma='auto', coef0=0.0, tol=0.001,\n",
    "                    C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "        self.clf.fit(self.X_train, torch.log(self.y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def __normalize_data(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return torch.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost(Model):\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        dtrain = xgb.DMatrix(X_train, label= torch.log(y_train))\n",
    "        evallist = [(dtrain, 'train')]\n",
    "        param = {'nthread': -1,\n",
    "                'max_depth': 7,\n",
    "                'eta': 0.02,\n",
    "                'silent': 1,\n",
    "                'objective': 'reg:linear',\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample': 0.7}\n",
    "        num_round = 3000\n",
    "        self.bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        dtest = xgb.DMatrix(feature)\n",
    "        return numpy.exp(self.bst.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistricalMedian(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.history = {}\n",
    "        self.feature_index = [1, 2, 3, 4]\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            key = tuple(x[self.feature_index])\n",
    "            self.history.setdefault(key, []).append(y)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        features = numpy.array(features)\n",
    "        features = features[:, self.feature_index]\n",
    "        guessed_sales = [numpy.median(self.history[tuple(feature)]) for feature in features]\n",
    "        return numpy.array(guessed_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.normalizer = Normalizer()\n",
    "        self.normalizer.fit(X_train)\n",
    "        self.clf = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance', p=1)\n",
    "        self.clf.fit(self.normalizer.transform(X_train), numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(self.normalizer.transform(X_val), y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(self.normalizer.transform(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_with_EntityEmbedding(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.one = nn.Sequential(nn.Embedding(1115, 10), nn.Flatten())\n",
    "        self.two = nn.Sequential(nn.Embedding(7, 6), nn.Flatten())\n",
    "        self.three = nn.Linear(1,1)\n",
    "        self.four = nn.Sequential(nn.Embedding(3, 2), nn.Flatten())\n",
    "        self.five = nn.Sequential(nn.Embedding(12, 6), nn.Flatten())\n",
    "        self.six = nn.Sequential(nn.Embedding(31, 10), nn.Flatten())\n",
    "        self.seven = nn.Sequential(nn.Embedding(12, 6), nn.Flatten())\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(41, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Network Weight Initializations\n",
    "        nn.init.uniform_(self.network[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.network[2].weight, -0.05, 0.05)\n",
    "        nn.init.xavier_uniform_(self.network[4].weight)\n",
    "        \n",
    "        # Embedding Weight Initializations\n",
    "        nn.init.uniform_(self.one[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.two[0].weight, -0.05, 0.05)\n",
    "        nn.init.xavier_uniform_(self.three.weight)\n",
    "        nn.init.uniform_(self.four[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.five[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.six[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.seven[0].weight, -0.05, 0.05)\n",
    "        \n",
    "        self.to(device)\n",
    "        self.fit(X_train,y_train, X_val, y_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        one = self.one(x[:,[1]])\n",
    "        two = self.two(x[:,[2]])\n",
    "        three=self.three(x[:, [3]].float())\n",
    "        four=self.four(x[:, [4]])\n",
    "        five=self.five(x[:,[5]])\n",
    "        six=self.six(x[:, [6]])\n",
    "        seven = self.seven(x[:, [7]])\n",
    "        concat = torch.cat([one, two, three, four, five, six, seven], dim=1)\n",
    "        output = self.network(concat)\n",
    "        return output\n",
    "    \n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val)/self.max_log_y\n",
    "    \n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val*self.max_log_y)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001, eps=1e-07)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in tqdm(train_loader,desc=f\"Training epoch {epoch+1}/{self.epochs}\",leave=False, colour='magenta'):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            print(f\"Loss on validation data: \", self.evaluate(X_val.to(device), y_val.to(device)))\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        with torch.inference_mode():\n",
    "            assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "            guessed_sales = self.guess(X_val) # Guess is implemented in children classes for inference\n",
    "            relative_err = torch.absolute((y_val - guessed_sales) / y_val) \n",
    "            result = torch.sum(relative_err) / len(y_val)\n",
    "            return result.item()\n",
    "    \n",
    "    def guess(self, features):\n",
    "        with torch.inference_mode():\n",
    "            result = self.forward(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_train_data.pickle', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "Xenc = enc.fit_transform(X)\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Xenc = torch.tensor(Xenc)\n",
    "y = torch.tensor(y)\n",
    "train_ratio = 0.9\n",
    "num_records = len(X)\n",
    "train_size = int(train_ratio * num_records)\n",
    "\n",
    "shuffle_data = False\n",
    "\n",
    "if shuffle_data:\n",
    "    print(\"Using shuffled data\")\n",
    "    sh = numpy.arange(X.shape[0])\n",
    "    numpy.random.shuffle(sh)\n",
    "    X = X[sh]\n",
    "    Xenc = Xenc[sh]\n",
    "    y = y[sh]\n",
    "\n",
    "X_train = X[:train_size]\n",
    "Xenc_train = Xenc[:train_size]\n",
    "X_val = X[train_size:]\n",
    "Xenc_val = Xenc[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_val = y[train_size:]\n",
    "\n",
    "def sample(X, Xenc, y, n):\n",
    "    '''random samples'''\n",
    "    num_row = X.shape[0]\n",
    "    indices = numpy.random.randint(num_row, size=n)\n",
    "    return X[indices, :], Xenc[indices, :], y[indices]\n",
    "\n",
    "X_train, Xenc_train, y_train = sample(X_train, Xenc_train, y_train, 200000)\n",
    "\n",
    "\n",
    "def evaluate_models(models, X, y):\n",
    "    assert(min(y) > 0)\n",
    "    guessed_sales = torch.stack([model.guess(X) for model in models])\n",
    "    mean_sales = guessed_sales.mean(axis=0)\n",
    "    relative_err = torch.absolute((y - mean_sales) / y)\n",
    "    result = torch.sum(relative_err) / len(y)\n",
    "    return result.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "models = []\n",
    "\n",
    "print(\"Fitting NN_with_EntityEmbedding...\")\n",
    "\n",
    "for i in range(5):\n",
    "    models.append(NN_with_EntityEmbedding(X_train, y_train, X_val, y_val))\n",
    "\n",
    "\n",
    "print(\"Evaluate combined models...\")\n",
    "print(\"Training error...\")\n",
    "r_train = evaluate_models(models, X_train.to(device), y_train.to(device))\n",
    "print(r_train)\n",
    "\n",
    "print(\"Validation error...\")\n",
    "r_val = evaluate_models(models, X_val.to(device), y_val.to(device))\n",
    "print(r_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super(NN, self).__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(1183, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # Network Weight Initializations\n",
    "        nn.init.uniform_(self.network[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.network[2].weight, -0.05, 0.05)\n",
    "        nn.init.xavier_uniform_(self.network[4].weight)\n",
    "        \n",
    "        self.to(device)\n",
    "        self.fit(X_train,y_train, X_val, y_val)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val) / self.max_log_y\n",
    "\n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val * self.max_log_y)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=False)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in tqdm(train_loader,desc=f\"Training epoch {epoch+1}/{self.epochs}\",leave=False, colour='magenta'):\n",
    "                inputs = inputs.float().to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            print(\n",
    "                \"Result on validation data: \",\n",
    "                self.evaluate(X_val.float().to(device), y_val.to(device)),\n",
    "            )\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert (\n",
    "            min(y_val) > 0\n",
    "        )  # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(\n",
    "            X_val\n",
    "        )  # Guess is implemented in children classes for inference\n",
    "        relative_err = torch.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = torch.sum(relative_err) / len(y_val)\n",
    "        return result\n",
    "\n",
    "    def guess(self, features):\n",
    "        with torch.no_grad():\n",
    "            result = self.network(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "models = []\n",
    "\n",
    "print(\"Fitting NN_with_EntityEmbedding...\")\n",
    "for i in range(5):\n",
    "    models.append(NN(Xenc_train, y_train, X_val, y_val))\n",
    "\n",
    "print(\"Evaluate combined models...\")\n",
    "print(\"Training error...\")\n",
    "r_train = evaluate_models(models, X_train.to(device), y_train.to(device))\n",
    "print(r_train)\n",
    "\n",
    "print(\"Validation error...\")\n",
    "r_val = evaluate_models(models, X_val.to(device), y_val.to(device))\n",
    "print(r_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
