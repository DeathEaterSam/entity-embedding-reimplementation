{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(123)\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to fetch previously saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_features(X, saved_embeddings_fname):\n",
    "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
    "    f_embeddings = open(saved_embeddings_fname, \"rb\") # Open the pickle file\n",
    "    embeddings = pickle.load(f_embeddings) # Load it\n",
    "\n",
    "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5} # The values are the indices of the embedded features\n",
    "    X_embedded = []\n",
    "\n",
    "    (num_records, num_features) = X.shape\n",
    "    for record in X:\n",
    "        embedded_features = []\n",
    "        for i, feat in enumerate(record):\n",
    "            feat = int(feat)\n",
    "            if i not in index_embedding_mapping.keys():\n",
    "                embedded_features += [feat]\n",
    "            else:\n",
    "                embedding_index = index_embedding_mapping[i]\n",
    "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
    "\n",
    "        X_embedded.append(embedded_features)\n",
    "\n",
    "    return numpy.array(X_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function takes the input data and returns a list of each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "\n",
    "    store_index = X[..., [1]]\n",
    "    X_list.append(store_index)\n",
    "\n",
    "    day_of_week = X[..., [2]]\n",
    "    X_list.append(day_of_week)\n",
    "\n",
    "    promo = X[..., [3]]\n",
    "    X_list.append(promo)\n",
    "\n",
    "    year = X[..., [4]]\n",
    "    X_list.append(year)\n",
    "\n",
    "    month = X[..., [5]]\n",
    "    X_list.append(month)\n",
    "\n",
    "    day = X[..., [6]]\n",
    "    X_list.append(day)\n",
    "\n",
    "    State = X[..., [7]]\n",
    "    X_list.append(State)\n",
    "\n",
    "    return X_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val) # Guess is implemented in children classes for inference\n",
    "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val) \n",
    "        result = numpy.sum(relative_err) / len(y_val)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = linear_model.LinearRegression() # this is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = RandomForestRegressor(n_estimators=200, verbose=True, max_depth=35, min_samples_split=2,\n",
    "                                         min_samples_leaf=1) # This is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistricalMedian(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.history = {}\n",
    "        self.feature_index = [1, 2, 3, 4]\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            key = tuple(x[self.feature_index])\n",
    "            self.history.setdefault(key, []).append(y)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        features = numpy.array(features)\n",
    "        features = features[:, self.feature_index]\n",
    "        guessed_sales = [numpy.median(self.history[tuple(feature)]) for feature in features]\n",
    "        return numpy.array(guessed_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.normalizer = Normalizer()\n",
    "        self.normalizer.fit(X_train)\n",
    "        self.clf = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance', p=1)\n",
    "        self.clf.fit(self.normalizer.transform(X_train), numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(self.normalizer.transform(X_val), y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(self.normalizer.transform(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_with_EntityEmbedding(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.zero = nn.Sequential(nn.Embedding(1115, 10), nn.Flatten())\n",
    "        self.one = nn.Sequential(nn.Embedding(7, 6), nn.Flatten())\n",
    "        self.two = nn.Linear(1,1)\n",
    "        self.three = nn.Sequential(nn.Embedding(3, 2), nn.Flatten())\n",
    "        self.four = nn.Sequential(nn.Embedding(12, 6), nn.Flatten())\n",
    "        self.five = nn.Sequential(nn.Embedding(31, 10), nn.Flatten())\n",
    "        self.six = nn.Sequential(nn.Embedding(21, 6), nn.Flatten())\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(41, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # self.fit(X_train,y_train, X_val, y_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        zero = self.zero(x[:,[1]])\n",
    "        one = self.one(x[:,[2]])\n",
    "        two=self.two(x[:, [3]].float())\n",
    "        three=self.three(x[:, [4]])\n",
    "        four=self.four(x[:,[5]])\n",
    "        five=self.five(x[:, [6]])\n",
    "        six = self.six(x[:, [7]])\n",
    "        concat = torch.cat([zero, one, two, three, four, five, six], dim=1)\n",
    "        output = self.network(concat)\n",
    "        return output\n",
    "    \n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val)/self.max_log_y\n",
    "    \n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val*self.max_log_y)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.00001)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=False)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val) # Guess is implemented in children classes for inference\n",
    "        relative_err = torch.absolute((y_val - guessed_sales) / y_val) \n",
    "        result = torch.sum(relative_err) / len(y_val)\n",
    "        return result\n",
    "    \n",
    "    def guess(self, features):\n",
    "        with torch.inference_mode():\n",
    "            result = self.forward(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_train_data.pickle', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "model = NN_with_EntityEmbedding(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\entity-embedding-reimplementation\\models.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# next(model.parameters()).device\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\entity-embedding-reimplementation\\models.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(inputs)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\entity-embedding-reimplementation\\models.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     zero \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mzero(x[:,[\u001b[39m1\u001b[39;49m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     one \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone(x[:,[\u001b[39m2\u001b[39m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sam/Desktop/ML%20Proj/entity-embedding-reimplementation/models.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     two\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtwo(x[:, [\u001b[39m3\u001b[39m]]\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Sam\\Desktop\\ML Proj\\MLProj\\Lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, X_val, y_val)\n",
    "# next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
