{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imports </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Normalizer, OneHotEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_train_data.pickle', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "Xenc = enc.fit_transform(X)\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Xenc = torch.tensor(Xenc, dtype=torch.float32)\n",
    "y = torch.tensor(y)\n",
    "train_ratio = 0.9\n",
    "num_records = len(X)\n",
    "train_size = int(train_ratio * num_records)\n",
    "\n",
    "shuffle_data = False\n",
    "\n",
    "if shuffle_data:\n",
    "    print(\"Using shuffled data\")\n",
    "    sh = numpy.arange(X.shape[0])\n",
    "    numpy.random.shuffle(sh)\n",
    "    X = X[sh]\n",
    "    Xenc = Xenc[sh]\n",
    "    y = y[sh]\n",
    "\n",
    "X_train = X[:train_size]\n",
    "Xenc_train = Xenc[:train_size]\n",
    "X_val = X[train_size:]\n",
    "Xenc_val = Xenc[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_val = y[train_size:]\n",
    "\n",
    "def sample(X, Xenc, y, n):\n",
    "    '''random samples'''\n",
    "    num_row = X.shape[0]\n",
    "    indices = numpy.random.randint(num_row, size=n)\n",
    "    return X[indices, :], Xenc[indices, :], y[indices]\n",
    "\n",
    "X_train, Xenc_train, y_train = sample(X_train, Xenc_train, y_train, 200000)\n",
    "\n",
    "\n",
    "def evaluate_models(models, X, y):\n",
    "    assert(min(y) > 0)\n",
    "    guessed_sales = torch.stack([model.guess(X) for model in models])\n",
    "    mean_sales = guessed_sales.mean(axis=0)\n",
    "    relative_err = torch.absolute((y - mean_sales) / y)\n",
    "    result = torch.sum(relative_err) / len(y)\n",
    "    return result.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to fetch previously saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_features(X, saved_embeddings_fname):\n",
    "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
    "    f_embeddings = open(saved_embeddings_fname, \"rb\") # Open the pickle file\n",
    "    embeddings = pickle.load(f_embeddings) # Load it\n",
    "\n",
    "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5} # The values are the indices of the embedded features\n",
    "    X_embedded = []\n",
    "\n",
    "    (num_records, num_features) = X.shape\n",
    "    for record in X:\n",
    "        embedded_features = []\n",
    "        for i, feat in enumerate(record):\n",
    "            feat = int(feat)\n",
    "            if i not in index_embedding_mapping.keys():\n",
    "                embedded_features += [feat]\n",
    "            else:\n",
    "                embedding_index = index_embedding_mapping[i]\n",
    "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
    "\n",
    "        X_embedded.append(embedded_features)\n",
    "\n",
    "    return numpy.array(X_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val)\n",
    "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = numpy.sum(relative_err) / len(y_val)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = linear_model.LinearRegression() # this is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.clf = RandomForestRegressor(n_estimators=200, verbose=True, max_depth=35, min_samples_split=2,\n",
    "                                         min_samples_leaf=1) # This is from sklearn not keras or tensorflow so please don't fail us\n",
    "        self.clf.fit(X_train, numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement support vector machine regression because they used sklearn, i copied it please dont DC us\n",
    "class SVM(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.__normalize_data()\n",
    "        self.clf = SVR(kernel='linear', degree=3, gamma='auto', coef0=0.0, tol=0.001,\n",
    "                    C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "        self.clf.fit(self.X_train, torch.log(self.y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def __normalize_data(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return torch.exp(self.clf.predict(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost(Model):\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        dtrain = xgb.DMatrix(X_train, label= torch.log(y_train))\n",
    "        evallist = [(dtrain, 'train')]\n",
    "        param = {'nthread': -1,\n",
    "                'max_depth': 7,\n",
    "                'eta': 0.02,\n",
    "                'silent': 1,\n",
    "                'objective': 'reg:linear',\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample': 0.7}\n",
    "        num_round = 3000\n",
    "        self.bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        dtest = xgb.DMatrix(feature)\n",
    "        return numpy.exp(self.bst.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistricalMedian(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.history = {}\n",
    "        self.feature_index = [1, 2, 3, 4]\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            key = tuple(x[self.feature_index])\n",
    "            self.history.setdefault(key, []).append(y)\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        features = numpy.array(features)\n",
    "        features = features[:, self.feature_index]\n",
    "        guessed_sales = [numpy.median(self.history[tuple(feature)]) for feature in features]\n",
    "        return numpy.array(guessed_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.normalizer = Normalizer()\n",
    "        self.normalizer.fit(X_train)\n",
    "        self.clf = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance', p=1)\n",
    "        self.clf.fit(self.normalizer.transform(X_train), numpy.log(y_train))\n",
    "        print(\"Result on validation data: \", self.evaluate(self.normalizer.transform(X_val), y_val))\n",
    "\n",
    "    def guess(self, feature):\n",
    "        return numpy.exp(self.clf.predict(self.normalizer.transform(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh2(nn.Module):\n",
    "  def _init_(self):\n",
    "    super()._init_()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return (F.tanh(x) + 1)/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NN_with_EntityEmbedding(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.one = nn.Sequential(nn.Embedding(1115, 50), nn.Flatten())\n",
    "        self.two = nn.Sequential(nn.Embedding(7, 50), nn.Flatten())\n",
    "        self.three = nn.Linear(1,50)\n",
    "        self.four = nn.Sequential(nn.Embedding(3, 50), nn.Flatten())\n",
    "        self.five = nn.Sequential(nn.Embedding(12, 50), nn.Flatten())\n",
    "        self.six = nn.Sequential(nn.Embedding(31, 50), nn.Flatten())\n",
    "        self.seven = nn.Sequential(nn.Embedding(12, 50), nn.Flatten())\n",
    "\n",
    "        \n",
    "        self.attend = nn.MultiheadAttention(50, 1, dropout=0.1)\n",
    "        self.layer1 = nn.Linear(350, 1000)\n",
    "        self.layer2 = nn.Linear(1000, 1000)\n",
    "        self.layer3 = nn.Linear(1000, 500)\n",
    "        self.layer4 = nn.Linear(500, 500)\n",
    "        self.layer5 = nn.Linear(500, 1)\n",
    "\n",
    "        # Network Weight Initializations\n",
    "        nn.init.kaiming_normal_(self.layer1.weight, mode='fan_out')\n",
    "        nn.init.kaiming_normal_(self.layer2.weight)\n",
    "        nn.init.kaiming_normal_(self.layer3.weight)\n",
    "        nn.init.kaiming_normal_(self.layer4.weight)\n",
    "        nn.init.xavier_normal_(self.layer5.weight)\n",
    "        \n",
    "        # Embedding Weight Initializations\n",
    "        nn.init.uniform_(self.one[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.two[0].weight, -0.05, 0.05)\n",
    "        nn.init.xavier_uniform_(self.three.weight)\n",
    "        nn.init.uniform_(self.four[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.five[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.six[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.seven[0].weight, -0.05, 0.05)\n",
    "        \n",
    "        self.to(device)\n",
    "        self.fit(X_train,y_train, X_val, y_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        one = self.one(x[:,[1]])\n",
    "        two = self.two(x[:,[2]])\n",
    "        three=self.three(x[:, [3]].float())\n",
    "        four=self.four(x[:, [4]])\n",
    "        five=self.five(x[:,[5]])\n",
    "        six=self.six(x[:, [6]])\n",
    "        seven = self.seven(x[:, [7]])\n",
    "        concat = torch.cat([one, two, three, four, five, six, seven], dim=1)\n",
    "        x = F.relu(self.layer1(concat)) # 350 -> 1000\n",
    "        y = x\n",
    "        x = F.relu(self.layer2(x)) # 1000 -> 1000\n",
    "        x = nn.Dropout(0.1)(x)\n",
    "        x = F.relu(self.layer3(x + y)) # 1000 -> 500\n",
    "        y = x\n",
    "        x = F.relu(self.layer4(x)) # 500 -> 500\n",
    "        nn.Dropout(0.1)(x)\n",
    "        x = self.layer5(x+y) # 500 -> 1\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val)/self.max_log_y\n",
    "    \n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val*self.max_log_y)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001, eps=1e-07)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = []\n",
    "            for inputs, targets in tqdm(train_loader,desc=f\"Training epoch {epoch+1}/{self.epochs}\",leave=False, colour='magenta', ncols=100):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                reg = 0\n",
    "                for param in self.parameters():\n",
    "                    reg += torch.norm(param, 2)\n",
    "                loss += 0.000001 * reg\n",
    "                train_loss.append(loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            self.train_losses.append(numpy.mean(train_loss))\n",
    "        self.val_losses.append(self.evaluate(X_val.to(device), y_val.to(device)))\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            print(f\"Loss on validation data: \", self.val_losses[-1])\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        with torch.inference_mode():\n",
    "            assert(min(y_val) > 0) # All sales are positive so predictions should be positive\n",
    "            guessed_sales = self.guess(X_val) # Guess is implemented in children classes for inference\n",
    "            relative_err = torch.absolute((y_val - guessed_sales) / y_val) \n",
    "            result = torch.sum(relative_err) / len(y_val)\n",
    "            return result.item()\n",
    "    \n",
    "    def guess(self, features):\n",
    "        with torch.inference_mode():\n",
    "            result = self.forward(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NN_with_EntityEmbedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/10:   0%|\u001b[35m                                                 \u001b[0m| 0/1563 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    0.51it/s]\u001b[0m\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation data:  0.10175375640392303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    0.05it/s]\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "models = []\n",
    "\n",
    "print(\"Fitting NN_with_EntityEmbedding...\")\n",
    "\n",
    "for i in range(5):\n",
    "    models.append(NN_with_EntityEmbedding(X_train, y_train, X_val, y_val))\n",
    "\n",
    "\n",
    "print(\"Evaluate combined models...\")\n",
    "print(\"Training error...\")\n",
    "r_train = evaluate_models(models, X_train.to(device), y_train.to(device))\n",
    "print(r_train)\n",
    "\n",
    "print(\"Validation error...\")\n",
    "r_val = evaluate_models(models, X_val.to(device), y_val.to(device))\n",
    "print(r_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2806423008441925]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for model in models:\n",
    "    plt.plot(model.val_losses, label=f\"Model {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(Model):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super(NN, self).__init__()\n",
    "        self.epochs = 10\n",
    "        self.max_log_y = max(torch.max(torch.log(y_train)), torch.max(torch.log(y_val)))\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(1183, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # Network Weight Initializations\n",
    "        nn.init.uniform_(self.network[0].weight, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.network[2].weight, -0.05, 0.05)\n",
    "        nn.init.xavier_uniform_(self.network[4].weight)\n",
    "\n",
    "        self.to(device)\n",
    "        self.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def _val_for_fit(self, val):\n",
    "        return torch.log(val) / self.max_log_y\n",
    "\n",
    "    def _val_for_pred(self, val):\n",
    "        return torch.exp(val * self.max_log_y)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        loss_fn = nn.L1Loss().to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        train_data = TensorDataset(X_train, self._val_for_fit(y_train))\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=False)\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, targets in tqdm(\n",
    "                train_loader,\n",
    "                desc=f\"Training epoch {epoch+1}/{self.epochs}\",\n",
    "                leave=False,\n",
    "                colour=\"magenta\",\n",
    "            ):\n",
    "                inputs = inputs.float().to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.forward(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            print(f\"Loss on validation data: \", self.evaluate(X_val.to(device), y_val.to(device)))\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        assert (min(y_val) > 0)  # All sales are positive so predictions should be positive\n",
    "        guessed_sales = self.guess(X_val)  # Guess is implemented in children classes for inference\n",
    "        relative_err = torch.absolute((y_val - guessed_sales) / y_val)\n",
    "        result = torch.sum(relative_err) / len(y_val)\n",
    "        return result.item()\n",
    "\n",
    "    def guess(self, features):\n",
    "        with torch.no_grad():\n",
    "            result = self.network(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/10:   2%|\u001b[35m‚ñè         \u001b[0m| 30/1563 [00:00<00:05, 295.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       6.35it/s]s]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting NN...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(\u001b[43mNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXenc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXenc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate combined models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining error...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 21\u001b[0m, in \u001b[0;36mNN.__init__\u001b[1;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     18\u001b[0m nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 44\u001b[0m, in \u001b[0;36mNN.fit\u001b[1;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m     39\u001b[0m         train_loader,\n\u001b[0;32m     40\u001b[0m         desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m         leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     42\u001b[0m         colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmagenta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     ):\n\u001b[1;32m---> 44\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numpy.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "models = []\n",
    "\n",
    "print(\"Fitting NN...\")\n",
    "for i in range(5):\n",
    "    models.append(NN(Xenc_train, y_train, Xenc_val, y_val))\n",
    "\n",
    "print(\"Evaluate combined models...\")\n",
    "print(\"Training error...\")\n",
    "r_train = evaluate_models(models, Xenc_train.to(device), y_train.to(device))\n",
    "print(r_train)\n",
    "\n",
    "print(\"Validation error...\")\n",
    "r_val = evaluate_models(models, Xenc_val.to(device), y_val.to(device))\n",
    "print(r_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
